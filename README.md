# ğŸ—ºï¸ğŸ›’ğŸ’°Onde Ã© Mais Barato Comprar em Curitiba: AnÃ¡lise dos PreÃ§os no Varejo por Bairro com Dados PÃºblicos

[<img src="https://img.shields.io/badge/Python-3.11-3776AB?style=for-the-badge&logo=python&logoColor=white" />](https://www.python.org/)
[<img src="https://img.shields.io/badge/Pandas-1.5-150458?style=for-the-badge&logo=pandas&logoColor=white" />](https://pandas.pydata.org/)
[<img src="https://img.shields.io/badge/Matplotlib-3.7-891845?style=for-the-badge&logo=matplotlib&logoColor=white" />](https://matplotlib.org/)
[<img src="https://img.shields.io/badge/Seaborn-0.12-09435b?style=for-the-badge&logo=seaborn&logoColor=white" />](https://seaborn.pydata.org/)

[**English Version ğŸ‡¬ğŸ‡§**](#english-version)

## ğŸ“– DescriÃ§Ã£o do Projeto

Este projeto consiste em uma anÃ¡lise exploratÃ³ria de dados sobre a dispersÃ£o de preÃ§os no setor de varejo alimentÃ­cio da cidade de Curitiba, utilizando dados pÃºblicos do programa "Clique Economia" referentes ao ano de 2024. O objetivo principal Ã© transformar mais de 700.000 registros de preÃ§os brutos em insights acionÃ¡veis que possam empoderar o consumidor em suas decisÃµes de compra.

O trabalho explora a dinÃ¢mica de preÃ§os atravÃ©s de trÃªs eixos principais: **geogrÃ¡fico** (comparando bairros), **competitivo** (comparando redes de supermercado) e **temporal** (analisando a evoluÃ§Ã£o dos preÃ§os ao longo dos meses).

---

## ğŸ¯ Objetivos

* Mapear a variaÃ§Ã£o de custos de uma cesta de consumo representativa entre os diferentes bairros.
* Comparar o posicionamento de preÃ§o das principais redes de supermercado.
* Identificar as categorias de produtos com maior volatilidade de preÃ§os.
* Sintetizar os achados em um guia prÃ¡tico para o consumidor curitibano.

---

## ğŸ› ï¸ Metodologia e Pipeline de Dados

O projeto foi desenvolvido em Python e seguiu um robusto pipeline de ETL (ExtraÃ§Ã£o, TransformaÃ§Ã£o e Carga) para garantir a qualidade e a consistÃªncia dos dados. As principais etapas foram:
1. **ExtraÃ§Ã£o:** AutomaÃ§Ã£o da coleta de centenas de arquivos CSV diÃ¡rios do portal de dados abertos.
2. **Limpeza de Dados:** Tratamento de valores nulos, correÃ§Ã£o de tipos de dados e remoÃ§Ã£o de duplicatas.
3. **Enriquecimento e NormalizaÃ§Ã£o:**
   * **NormalizaÃ§Ã£o GeogrÃ¡fica:** ExtraÃ§Ã£o e padronizaÃ§Ã£o dos bairros de Curitiba.
   * **PadronizaÃ§Ã£o de Redes:** UnificaÃ§Ã£o de nomes variantes de uma mesma rede de supermercado.
   * **Sistema de CategorizaÃ§Ã£o:** Desenvolvimento de um classificador hierÃ¡rquico (`categoria_n1`, `categoria_n2`) baseado em um sistema de regras de dupla camada para classificar mais de 700.000 descriÃ§Ãµes de produtos.

---

## ğŸ“ˆ Amostra dos Resultados

* **[Ranking de Bairros por Custo da Cesta Essencial](./results/1_grafico_ranking_bairros.png)**  
  ComparaÃ§Ã£o entre os 10 bairros mais caros e mais baratos para uma cesta padrÃ£o.

* **[Matriz de Competitividade: PreÃ§o por Rede e Categoria](./results/3_grafico_matriz_competitividade_redes_macrocategoria.png)**  
  Heatmap que revela o posicionamento de cada rede de supermercado.

* **[EvoluÃ§Ã£o Temporal das Principais Subcategorias](./results/painel_evolucao_subcategorias.png)**  
  VisualizaÃ§Ã£o da jornada de preÃ§os das 12 subcategorias mais relevantes ao longo de 2024.

* **[Guia PrÃ¡tico: A Rede Mais Barata por Bairro](./results/Ranking_RedesMaisBaratas_Bairro.png)**  
  Tabela final indicando a rede com menor custo mÃ©dio por bairro.

---

### ğŸ“‚ Quer ver todos os grÃ¡ficos e planilhas de resultados?

Quer conferir todos os resultados? DÃ¡ uma olhada ğŸ‘‰ [**Clique aqui para acessar a pasta `/results`**](./results) â€” tem tudo lÃ¡: grÃ¡ficos, tabelas e planilhas do projeto.

---

## ğŸš€ Como Executar o Projeto

1. Clone este repositÃ³rio.
2. Crie um ambiente virtual (`python -m venv .venv`) e ative-o.
3. Instale as dependÃªncias: `pip install -r requirements.txt`.
4. Coloque os arquivos de dados brutos na pasta `/dados`.
5. Execute os scripts na ordem: `01_...`, `02_...`, `03_...`.
6. Os resultados serÃ£o gerados na pasta `/resultados`.

---

## ğŸ‘¨â€ğŸ’» Autor

**Lucas Alejandro Terres**  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/lucasalejandroterres/)  
ğŸ“§ lucasalejandroterres@gmail.com

&nbsp;  
&nbsp;  

---

<a name="english-version"></a>

# ğŸ—ºï¸ğŸ›’ğŸ’°Where to Shop Cheaper in Curitiba: Neighborhood Grocery Price Analysis Based on Public Data

[<img src="https://img.shields.io/badge/Python-3.11-3776AB?style=for-the-badge&logo=python&logoColor=white" />](https://www.python.org/)
[<img src="https://img.shields.io/badge/Pandas-1.5-150458?style=for-the-badge&logo=pandas&logoColor=white" />](https://pandas.pydata.org/)
[<img src="https://img.shields.io/badge/Matplotlib-3.7-891845?style=for-the-badge&logo=matplotlib&logoColor=white" />](https://matplotlib.org/)
[<img src="https://img.shields.io/badge/Seaborn-0.12-09435b?style=for-the-badge&logo=seaborn&logoColor=white" />](https://seaborn.pydata.org/)

[**Portuguese Version ğŸ‡§ğŸ‡·**](#ï¸-onde-Ã©-mais-barato-comprar-em-curitiba-anÃ¡lise-dos-preÃ§os-no-varejo-por-bairro-com-dados-pÃºblicos)

## ğŸ“– About The Project

This project consists of an exploratory data analysis of price dispersion in the food retail sector of Curitiba, Brazil, using public data from the "Clique Economia" program for the year 2024. The main goal is to transform over 700,000 raw price records into actionable intelligence that can empower consumers in their purchasing decisions.

The work explores price dynamics across three main axes: **geographical** (comparing neighborhoods), **competitive** (comparing supermarket chains), and **temporal** (analyzing price evolution over the months).

---

## ğŸ¯ Key Objectives

* Map the cost variation of a representative consumer basket across different city neighborhoods.
* Compare the price positioning of the main supermarket chains.
* Identify the product categories with the highest price volatility.
* Deliver a practical guide for consumers in Curitiba.

---

## ğŸ› ï¸ Methodology & Data Pipeline

1. **Extraction:** Automated download of daily CSV files from the open data portal.
2. **Cleaning:** Null handling, type fixing, and deduplication.
3. **Enrichment:**
   * **Neighborhood Normalization**
   * **Retail Chain Harmonization**
   * **Hierarchical Product Classification**

---

## ğŸ“ˆ Results Showcase

* **[Neighborhood Ranking](./results/1_grafico_ranking_bairros.png)** â€“ 10 most and least expensive neighborhoods.
* **[Competitiveness Matrix](./results/3_grafico_matriz_competitividade_redes_macrocategoria.png)** â€“ Heatmap showing pricing strength by chain.
* **[Price Evolution Dashboard](./results/painel_evolucao_subcategorias.png)** â€“ Price behavior over time.
* **[Cheapest Chain by Neighborhood](./results/Ranking_RedesMaisBaratas_Bairro.png)** â€“ Final table with consumer guide.

---

Want to check out all the results?  
Take a look ğŸ‘‰ [**Full results folder here**](./results) â€” it's all there: plots, tables, and CSVs.

---

## ğŸš€ How to Run

1. Clone this repository.
2. Create a virtual environment: `python -m venv .venv`
3. Activate it and run: `pip install -r requirements.txt`
4. Add your data to the `/dados` folder.
5. Run the scripts in order.
6. Outputs will be saved in `/resultados`.

---

## ğŸ‘¨â€ğŸ’» Author

**Lucas Alejandro Terres**  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/lucasalejandroterres/)  
ğŸ“§ lucasalejandroterres@gmail.com
